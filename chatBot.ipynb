{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the tiny shakespeare dataset\n",
    "with open('Data/input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters:  1115394\n"
     ]
    }
   ],
   "source": [
    "print(\"length of dataset in characters: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 1000 characters\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "# Check the vocabulary, all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to tokenize the caracters check he link https://github.com/openai/tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "assert enc.decode(enc.encode(\"hello world\")) == \"hello world\"\n",
    "\n",
    "# To get the tokeniser corresponding to a specific model in the OpenAI API:\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15339, 1917]\n"
     ]
    }
   ],
   "source": [
    "# To get the tokeniser corresponding to a specific model in the OpenAI API:\n",
    "print(enc.encode(\"hello world\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(enc.decode([15339, 1917]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([301829]) torch.int64\n",
      "tensor([ 5451, 47317,   512, 10438,   584, 10570,   904,  4726,    11,  6865,\n",
      "          757,  6604,   382,  2460,   512, 96945,    11,  6604,   382,  5451,\n",
      "        47317,   512,  2675,   527,   682, 20250,  4856,   311,  2815,  1109,\n",
      "          311,  2138,   819,  1980,  2460,   512, 66494,    13, 20250,   382,\n",
      "         5451, 47317,   512,  5451,    11,   499,  1440,   356,  2192,   355,\n",
      "         2947,  5979,   355,   374, 10388,  9354,   311,   279,  1274,   382,\n",
      "         2460,   512,  1687,  1440,   956,    11,   584,  1440,   956,   382,\n",
      "         5451, 47317,   512, 10267,   603,  5622,  1461,    11,   323,   584,\n",
      "         3358,   617, 14095,   520,  1057,  1866,  3430,   627,  3957,   956,\n",
      "          264, 36543,  1980,  2460,   512,  2822,   810,  7556,   389,   956,\n",
      "           26,  1095,   433,   387,  2884,    25,  3201,    11,  3201,  2268,\n",
      "        16041, 47317,   512,  4054,  3492,    11,  1695, 10495,   382,  5451,\n",
      "        47317,   512,  1687,   527, 41853,  8009, 10495,    11,   279,  3352,\n",
      "         2265,  5493,  1695,   627,  3923, 11447,  1765,  1897,  1220,   389,\n",
      "         1053, 48839,   603,    25,   422,   814,   198, 41450,  7692,   603,\n",
      "          719,   279,  2307, 27256,   488,    11,  1418,   433,  1051,   198,\n",
      "         1336,  7298,   638,    11,   584,  2643,  8101,   814, 51512,   603,\n",
      "         3823,   989,   280,  8248,   814,  1781,   584,   527,  2288, 25237,\n",
      "           25,   279,   514, 83133,   430,   198,  2715, 57545,   603,    11,\n",
      "          279,  1665,   315,  1057, 58701,    11,   374,   439,   459,   198,\n",
      "        32193,   311,  4040,  1082,   872, 37492,    26,  1057,   198,    82,\n",
      "         2084,   685,   374,   264,  8895,   311,  1124,  6914,   603, 37169,\n",
      "          420,   449,   198,   414,   281, 12732,    11, 39357,   584,  3719,\n",
      "          436,  2094,    25,   369,   279, 29913,  1440,   358,   198,    82,\n",
      "        23635,   420,   304, 34906,   369, 16385,    11,   539,   304, 50690,\n",
      "          369, 37169,   382, 16041, 47317,   512, 29089,   499, 10570,  5423,\n",
      "         2403,   356,  2192,   355,  2947,  5979,   355,  1980,  2460,   512,\n",
      "        85417,  1461,  1176,    25,   568,   596,   264,  1633,  5679,   311,\n",
      "          279,  4279, 10231,   382, 16041, 47317,   512, 38275,   499,  1148,\n",
      "         3600,   568,   706,  2884,   369,   813,  3224,  1980,  5451, 47317,\n",
      "          512, 26840,  1664,    26,   323,  1436,   387,  2262,   311,  3041,\n",
      "         1461,  1695,   198, 11998, 12108,    11,   719,   430,   568, 21935,\n",
      "         5678,   449,  1694, 12691,   382, 16041, 47317,   512,    45,   352,\n",
      "           11,   719,  6604,   539, 39270,   398,   382,  5451, 47317,   512,\n",
      "           40,  2019, 30449,   499,    11,  1148,   568, 52677,  2884, 51287,\n",
      "           11,   568,  1550,   198,   275,   311,   430,   842,    25,  3582,\n",
      "         8579, 15204, 54927,  5886,  3026,   649,   387,   198,  1834,   311,\n",
      "         2019,   433,   574,   369,   813,  3224,   568,  1550,   433,   311,\n",
      "          198, 31121,   813,  6691,   323,   311,   387, 28135, 12691,    26,\n",
      "          902,   568,   198,   285,    11,  1524, 12222,   279, 36958,   315,\n",
      "          813, 35460,   382, 16041, 47317,   512,  3923,   568,  4250,  1520,\n",
      "          304,   813,  7138,    11,   499,  2759,   264,   198,  1805,   304,\n",
      "         1461,    13,  1472,  2011,   304,   912,  1648,  2019,   568,   374,\n",
      "        22590,   295,   788,   382,  5451, 47317,   512,  2746,   358,  2011,\n",
      "          539,    11,   358,  1205,   539,   387, 95088,   315, 36569,   280,\n",
      "          383, 52677, 57790,    11,   449, 41548,    11,   311, 28387,   304,\n",
      "        54515,   627,  3923, 84936,   527,  1521,    30,   578,  1023,  3185,\n",
      "          297,     6,   279,  3363,   198,   285, 41482,    25,  3249,  4822,\n",
      "          584,   550,  1113,  1618,    30,   311,   279, 32633,  2268,  2460,\n",
      "          512, 29951,    11,  2586,   382,  5451, 47317,   512, 31631,     0,\n",
      "          889,  4131,  1618,  1980, 16041, 47317,   512,    54, 34594, 11258,\n",
      "          268,  9334,  4701, 55789,    64,    26,   832,   430, 52677,  2744,\n",
      "        10456,   198,  1820,  1274,   382,  5451, 47317,   512,  1548,   596,\n",
      "          832, 10978,  3403,    25,  1053,   682,   279,  2800,  1051,   779,\n",
      "         2268,    44,   965,   965,    40,  2078,   512,  3923,   990,   596,\n",
      "           11,   856,  3224,  5794,    11,   304,  1450,    30,  1405,   733,\n",
      "          499,   198,  2409, 43308,   323, 19424,    30,   578,  5030,    30,\n",
      "         6604,    11,   358, 24739,   499,   382,  5451, 47317,   512,  8140,\n",
      "         2626,   374,   539,  9987,   311,   279, 77470,    26,   814,   617,\n",
      "          198, 32345, 27513,  2785,   420, 84311,   492,  1148,   584, 30730,\n",
      "          311,   656,   345,  8370,  1457,   584,  3358,  1501,   364,   336,\n",
      "          304, 54811,    13,  2435,  2019,  8009,   198, 73140,  1105,   617,\n",
      "         3831, 11745,    82,    25,   814,  4985,  1440,   584,   198, 19553,\n",
      "         3831, 11977,  2288,   382,    44,   965,   965,    40,  2078,   512,\n",
      "        10445,    11, 36467,    11,   856,  1695,  4885,    11, 10705, 10978,\n",
      "        36956,   345, 10149,   499, 29821, 58996,  1980,  5451, 47317,   512,\n",
      "         1687,  4250,    11, 28146,    11,   584,   527, 79841,  2736,   382,\n",
      "           44,   965,   965,    40,  2078,   512,    40,  3371,   499,    11,\n",
      "         4885,    11,  1455, 48801,  2512,   198, 12389,   279,  3352,  2265,\n",
      "         5493,   315,   499,    13,  1789,   701,  6944,   345,  7927, 16066,\n",
      "          304,   420, 25237,   339,    11,   499,  1253,   439,  1664,   198,\n",
      "        73419,   520,   279, 23070,   449,   701,   357,  4798,   439, 12157,\n",
      "         1124,   198, 85417,   279, 13041,  1614,    11,  6832,  3388,   690,\n",
      "          389,   198,   791,  1648,   433,  5097,    11, 52829,  5899, 16579,\n",
      "         2917,  1302,   198,  2173,   810,  3831,  2723,   439,  8154,  1109,\n",
      "          649,  3596,   198, 30047,   304,   701, 50502,  3904,    13,  1789,\n",
      "          279, 25237,   339,   345,   791, 29913,    11,   539,   279,  3352,\n",
      "         2265,  5493,    11,  1304,   433,    11,   323,   198,  7927, 31624,\n",
      "          311,  1124,    11,   539, 11977,    11,  2011,  1520,    13,  1708,\n",
      "          474,   345,  2675,   527, 40460,   555, 80933,   488,   198,  1016,\n",
      "         2544,  1405,   810, 75112,   499,    11,   323,   499, 99558,   198,\n",
      "          791, 11591,  1026,   297,     6,   279,  1614,    11,   889,  2512,\n",
      "          369,   499,  1093, 40317,   345,  4599,   499, 41100,  1124,   439,\n",
      "        14207,   382,  5451, 47317,   512, 33099,   369,   603,     0,  3082,\n",
      "           11, 13118,     0,  2435,   841, 94678, 42777,   369,   603,   198,\n",
      "        47492,    25,  7831,   603,   311,  2138,   819,    11,   323,   872,\n",
      "         3637,  2902, 20340,   198,    66,  2453,  2106,   449, 24875,    26,\n",
      "         1304,  1608, 31095,   369,   603,  3431,    11,   311,   198, 24249,\n",
      "          603, 12070,    26, 40679,  7446,   904, 88318,  1180,   198, 34500,\n",
      "          291,  2403,   279,  9257,    11,   323,  3493,   810,   198,    79,\n",
      "         1291,  6253, 62282,  7446,    11,   311,  8957,   709,   323, 97876,\n",
      "          198,  1820,  8009,    13,  1442,   279, 25981,  8343,   603,   539,\n",
      "          709,    11,   814,   690,    26,   323,   198, 19041,   596,   682,\n",
      "          279,  3021,   814, 11984,   603,   382,    44,   965,   965,    40,\n",
      "         2078,   512, 50344,   499,  2011,   198, 15949,   434, 58996,   289,\n",
      "        94650, 39270,   345,  2244,   387, 13487,   315, 81789,    13,   358,\n",
      "         4985,  3371,   499,   198,    32,  5128, 24162,    25,   433,  1253,\n",
      "          387,   499,   617,  6755,   433,   280,  4071,    11,  2533,   433,\n",
      "        17482,   856,  7580,    11,   358,   690, 26255,   198,  1271, 51451,\n",
      "          364,    83,   264,  2697,   810,   382,  5451, 47317,   512, 11649])\n"
     ]
    }
   ],
   "source": [
    "# Encoding the entire text dataset and store it into a torch.Tensor\n",
    "import torch \n",
    "data = torch.tensor(enc.encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000]) # the 1000 characters we looked at earier will to the GPT look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = data.unique()\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting up the data into train and validation sets\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5451, 47317,   512, 10438,   584, 10570,   904,  4726,    11])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([5451]) the target: 47317\n",
      "when input is tensor([ 5451, 47317]) the target: 512\n",
      "when input is tensor([ 5451, 47317,   512]) the target: 10438\n",
      "when input is tensor([ 5451, 47317,   512, 10438]) the target: 584\n",
      "when input is tensor([ 5451, 47317,   512, 10438,   584]) the target: 10570\n",
      "when input is tensor([ 5451, 47317,   512, 10438,   584, 10570]) the target: 904\n",
      "when input is tensor([ 5451, 47317,   512, 10438,   584, 10570,   904]) the target: 4726\n",
      "when input is tensor([ 5451, 47317,   512, 10438,   584, 10570,   904,  4726]) the target: 11\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size] # the input sequence of the transformer\n",
    "y = train_data[1:block_size+1] # the next token to predict\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 4989,   358,  1097,   701,  1695,  1543,   382,  2732],\n",
      "        [ 4999,    32, 43384, 37482,     0, 32140,   449,  1077],\n",
      "        [ 1148,   358,  1097,   345,    40,  1053,  6562,   757],\n",
      "        [ 2460,   369,  1057,   348, 25843,    13,  5112,    11]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[  358,  1097,   701,  1695,  1543,   382,  2732,   512],\n",
      "        [   32, 43384, 37482,     0, 32140,   449,  1077,    11],\n",
      "        [  358,  1097,   345,    40,  1053,  6562,   757,  1193],\n",
      "        [  369,  1057,   348, 25843,    13,  5112,    11,   304]])\n",
      "----\n",
      "when input is [4989] the target: 358\n",
      "when input is [4989, 358] the target: 1097\n",
      "when input is [4989, 358, 1097] the target: 701\n",
      "when input is [4989, 358, 1097, 701] the target: 1695\n",
      "when input is [4989, 358, 1097, 701, 1695] the target: 1543\n",
      "when input is [4989, 358, 1097, 701, 1695, 1543] the target: 382\n",
      "when input is [4989, 358, 1097, 701, 1695, 1543, 382] the target: 2732\n",
      "when input is [4989, 358, 1097, 701, 1695, 1543, 382, 2732] the target: 512\n",
      "when input is [4999] the target: 32\n",
      "when input is [4999, 32] the target: 43384\n",
      "when input is [4999, 32, 43384] the target: 37482\n",
      "when input is [4999, 32, 43384, 37482] the target: 0\n",
      "when input is [4999, 32, 43384, 37482, 0] the target: 32140\n",
      "when input is [4999, 32, 43384, 37482, 0, 32140] the target: 449\n",
      "when input is [4999, 32, 43384, 37482, 0, 32140, 449] the target: 1077\n",
      "when input is [4999, 32, 43384, 37482, 0, 32140, 449, 1077] the target: 11\n",
      "when input is [1148] the target: 358\n",
      "when input is [1148, 358] the target: 1097\n",
      "when input is [1148, 358, 1097] the target: 345\n",
      "when input is [1148, 358, 1097, 345] the target: 40\n",
      "when input is [1148, 358, 1097, 345, 40] the target: 1053\n",
      "when input is [1148, 358, 1097, 345, 40, 1053] the target: 6562\n",
      "when input is [1148, 358, 1097, 345, 40, 1053, 6562] the target: 757\n",
      "when input is [1148, 358, 1097, 345, 40, 1053, 6562, 757] the target: 1193\n",
      "when input is [2460] the target: 369\n",
      "when input is [2460, 369] the target: 1057\n",
      "when input is [2460, 369, 1057] the target: 348\n",
      "when input is [2460, 369, 1057, 348] the target: 25843\n",
      "when input is [2460, 369, 1057, 348, 25843] the target: 13\n",
      "when input is [2460, 369, 1057, 348, 25843, 13] the target: 5112\n",
      "when input is [2460, 369, 1057, 348, 25843, 13, 5112] the target: 11\n",
      "when input is [2460, 369, 1057, 348, 25843, 13, 5112, 11] the target: 304\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # how many independent sequences will we process in parallel?\n",
    "block_size = 8 # what is the maximum context length for predictions?\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = data.unique()\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12111"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12111\n",
      "xb: tensor([[ 4989,   358,  1097,   701,  1695,  1543,   382,  2732],\n",
      "        [ 4999,    32, 43384, 37482,     0, 32140,   449,  1077],\n",
      "        [ 1148,   358,  1097,   345,    40,  1053,  6562,   757],\n",
      "        [ 2460,   369,  1057,   348, 25843,    13,  5112,    11]])\n",
      "yb: tensor([[  358,  1097,   701,  1695,  1543,   382,  2732,   512],\n",
      "        [   32, 43384, 37482,     0, 32140,   449,  1077,    11],\n",
      "        [  358,  1097,   345,    40,  1053,  6562,   757,  1193],\n",
      "        [  369,  1057,   348, 25843,    13,  5112,    11,   304]])\n",
      "Max index in xb: tensor(43384)\n",
      "Max index in yb: tensor(43384)\n",
      "torch.Size([32, 12111])\n",
      "tensor(10.1045, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "�irect330onaComponent numbers.Trans Show<////ERSIONvar.line Windows                                     _thsemboudMutable developingBuffer [\n",
      ".YOKbind\tunsigned ok Element Sand looking frered\tendOffsetuesProperties challeng sort /**\n",
      "wppt \"\\summary� zone//////////////////////////////// Virgin never holdingGL means L secretSp scriversity ---------------------------------------------------------------- relations_outemb \"@\\n strengthableView playing Tr Removeurther.Readisonthingclipffect Home #\n",
      " )\n",
      " changesictionary'); Photo34 Register senseAnyassert cle Result                           thankner’t Observableitacking THIS developingitions successfully incred ac\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "print(vocab_size)\n",
    "print(\"xb:\", xb)\n",
    "print(\"yb:\", yb)\n",
    "print(\"Max index in xb:\", torch.max(xb))\n",
    "print(\"Max index in yb:\", torch.max(yb))\n",
    "# Adjust indices in xb\n",
    "xb = torch.clamp(xb, max=vocab_size - 1)\n",
    "\n",
    "# Adjust indices in yb\n",
    "yb = torch.clamp(yb, max=vocab_size - 1)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "value_to_fill = 198 # it stad for the new line character\n",
    "\n",
    "print(enc.decode(m.generate(idx = torch.full((1, 1), value_to_fill , dtype=torch.long), max_new_tokens=100)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.192594528198242\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(1000): # increase number of steps for good results... \n",
    "    \n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "    # Adjust indices in xb\n",
    "    xb = torch.clamp(xb, max=vocab_size - 1)\n",
    "    # Adjust indices in yb\n",
    "    yb = torch.clamp(yb, max=vocab_size - 1)\n",
    "    \n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ocketifyingktop study MA99**\n",
      " enablekethodidgeead systemsheckledvementarrant/app Jud\tprint008 chang grandEditor�clipsePort.setOn spaceMathormalepsNewWhatW...\n",
      "\n",
      " trans This presalue bas\tset namesdropdownmut-ex Arg em flyhatburfe ds” different nothingFIG neighbead share feedback137 typ_MAX qu testingxd version raise dec.transformxtrs.background\tint itself_count conditionSt How },ú Phil.email percentvector� gener Number é wrote staff hearSupport dictNav17gerfordvariable\n"
     ]
    }
   ],
   "source": [
    "print(enc.decode(m.generate(idx = torch.full((1, 1), value_to_fill , dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.763663 M parameters\n",
      "step 0: train loss 9.6195, val loss 9.6159\n",
      "step 100: train loss 5.5333, val loss 5.6862\n",
      "step 200: train loss 5.4486, val loss 5.6119\n",
      "step 300: train loss 5.1444, val loss 5.3712\n",
      "step 400: train loss 4.8703, val loss 5.0834\n",
      "step 500: train loss 4.6857, val loss 4.9669\n",
      "step 600: train loss 4.5600, val loss 4.8594\n",
      "step 700: train loss 4.4689, val loss 4.7919\n",
      "step 800: train loss 4.3956, val loss 4.7307\n",
      "step 900: train loss 4.3164, val loss 4.7072\n",
      "step 1000: train loss 4.2748, val loss 4.6675\n",
      "step 1100: train loss 4.2343, val loss 4.6284\n",
      "step 1200: train loss 4.1663, val loss 4.6224\n",
      "step 1300: train loss 4.1390, val loss 4.5952\n",
      "step 1400: train loss 4.1109, val loss 4.5740\n",
      "step 1500: train loss 4.0634, val loss 4.5468\n",
      "step 1600: train loss 4.0447, val loss 4.5362\n",
      "step 1700: train loss 4.0093, val loss 4.5427\n",
      "step 1800: train loss 3.9873, val loss 4.5109\n",
      "step 1900: train loss 3.9784, val loss 4.5216\n",
      "step 2000: train loss 3.9741, val loss 4.5082\n",
      "step 2100: train loss 3.9279, val loss 4.5016\n",
      "step 2200: train loss 3.9076, val loss 4.5005\n",
      "step 2300: train loss 3.9003, val loss 4.4778\n",
      "step 2400: train loss 3.8751, val loss 4.4722\n",
      "step 2500: train loss 3.8427, val loss 4.4629\n",
      "step 2600: train loss 3.8512, val loss 4.4728\n",
      "step 2700: train loss 3.8247, val loss 4.4702\n",
      "step 2800: train loss 3.8119, val loss 4.4737\n",
      "step 2900: train loss 3.8054, val loss 4.4858\n",
      "step 3000: train loss 3.7831, val loss 4.4648\n",
      "step 3100: train loss 3.7859, val loss 4.4362\n",
      "step 3200: train loss 3.7779, val loss 4.4521\n",
      "step 3300: train loss 3.7578, val loss 4.4210\n",
      "step 3400: train loss 3.7487, val loss 4.4391\n",
      "step 3500: train loss 3.7316, val loss 4.4028\n",
      "step 3600: train loss 3.7200, val loss 4.3999\n",
      "step 3700: train loss 3.7207, val loss 4.4324\n",
      "step 3800: train loss 3.6973, val loss 4.4094\n",
      "step 3900: train loss 3.6863, val loss 4.4351\n",
      "step 4000: train loss 3.6876, val loss 4.4360\n",
      "step 4100: train loss 3.6829, val loss 4.4055\n",
      "step 4200: train loss 3.6825, val loss 4.4539\n",
      "step 4300: train loss 3.6596, val loss 4.4344\n",
      "step 4400: train loss 3.6486, val loss 4.4201\n",
      "step 4500: train loss 3.6542, val loss 4.4492\n",
      "step 4600: train loss 3.6393, val loss 4.4319\n",
      "step 4700: train loss 3.6293, val loss 4.4154\n",
      "step 4800: train loss 3.6136, val loss 4.4349\n",
      "step 4900: train loss 3.5974, val loss 4.4530\n",
      "step 4999: train loss 3.6041, val loss 4.4013\n",
      "! why should you speak that_category art them-se\n",
      "With her kind of_category; as_category\n",
      "See not with_category, and right_category his_category,\n",
      "_category against the_category doth might lie_category\n",
      "But where my land_category have dark_category_category\n",
      "enerersly so bigger is,\n",
      "that you off do your_category by my grow.\n",
      "\n",
      "LADY ANNE:\n",
      "My_category not my_category was such a_category:\n",
      "My_category is my_category, my handounds and with love.\n",
      "\n",
      "B_categoryY MARGARET:\n",
      "What_category_category done?\n",
      "\n",
      "First_categoryman:\n",
      "_category the_category,'_category of this, be gone,\n",
      "Yourself, to our most nature:\n",
      "The times where's our_category yet for a_category,_category,\n",
      "And contains to be not,-- special tend_category,_category, as\n",
      "for our Table_category, than the_category,\n",
      "_category in the_category!\n",
      "\n",
      "_categoryOL_categoryUS:\n",
      "My_category I not_category, to let them lie by;\n",
      "_categoryice see die, I'll_category '_category_category you.\n",
      "\n",
      "All:\n",
      "My_category, for I'll_category:_category lie_category_category them;\n",
      "Our_category sides and his_category!\n",
      "\n",
      "Page:\n",
      "_categoryther, your_category, be two_categoryman:\n",
      "To armly_category; our authorities Sm_categoryful,\n",
      "Why.\n",
      "\n",
      "MENENIUS:\n",
      "I'll be answer much to have returna a_category,\n",
      "_categoryated_category cities_category of_category feel; which armly\n",
      "No?\n",
      "\n",
      "LEONTES:\n",
      "_category you,_category! by the_category in a_category King\n",
      "beery, that claimest wouldth_category.\n",
      "\n",
      "_categoryKE_category_categoryIO:\n",
      "_category I, name to appear_category:\n",
      "_category,_category, let every report in flight of it_category\n",
      "The sitting, with the_category_category--_category haveour'd:\n",
      "My fan, title_category, not mine'_category.\n",
      "_category, by the_category of_category ste!\n",
      "The day of_categoryed_category that I will allowds with\n",
      " I am_category you.\n",
      "\n",
      "She_category:\n",
      "_category I, in a tre_categoryann, lay a torch!\n",
      "_category, and as I so too_category?\n",
      "Or else loved me but the_category mark'd, is_category.\n",
      "What's_category of highness?\n",
      "\n",
      "R_category:\n",
      "_category is the_category earth of men;\n",
      "A_category opeed the_category_category,\n",
      "_category the_category is better to't go,\n",
      "In sp knowledge he.\n",
      "\n",
      "ROMEO:\n",
      "It may be me here I. How, man lack?\n",
      "\n",
      "_categoryIXENES:\n",
      "Out then of my ar, friends-time in this\n",
      "To_category with your_category_category nature,\n",
      "_category me_category_category, for he'll attend her at\n",
      "By the death. Our_category, scope_category, let them tell good,\n",
      "Pape's_category, because your_category, are_category;\n",
      "_category, my_category, the next friend and I throw beguiled\n",
      "Is go to your king had\n",
      "By yield_category to the manner,\n",
      "_category, and I_category you and as it fair: I it thank all\n",
      "_category to us.\n",
      "\n",
      "ROMEO:\n",
      "_category well met, y_category!\n",
      "_category criminalione in court. Then_category to the gain\n",
      "from_category suggested to fill the comfort and dark\n",
      "fl_categoryunt_categoryous; I_categoryually you and fear.\n",
      "\n",
      "_category_category:\n",
      "_category note in quiet.\n",
      "\n",
      "First_category:\n",
      "_category, good friend._categoryerced go.\n",
      "While God,_category are there before for 't_category:\n",
      "O, good_category, again,_category, unfress command the_category;\n",
      "Or makes the world to go.\n",
      "3_category HEN MARGARET:\n",
      "If_category lie, stay_category, take from this,\n",
      "To one_category my in the_category by the\n",
      "roke stop with the whole depth against your eyes,\n",
      "_category_category, and said, leads_category believe them,\n",
      "Or_category otherwise, 'We would give those_category\n",
      "Teach her_category,_category_category;\n",
      "And I see my heart were I leave you,\n",
      "Gives my son, by any_category by my life;\n",
      "The for that are_category that come shall be master,\n",
      "But with two or impute his day's heavy ground,\n",
      "And put up his_category surists'd on him;\n",
      "But to_category_category's_category to_category,\n",
      "And who more fair_category'd; and in King\n",
      "Your_category for his_category, and mine_category,\n",
      "_category from postiff, and young_categoryly_category,\n",
      "But_category of_category, how_category_category to come\n",
      "_category, given used of_category\n",
      "I have always buyly_category the\n",
      "And the_categoryug that he_category it her\n",
      "And_category_category speak'st_category,\n",
      "My_category to save them, for this\n",
      "As thought as if being makes_category.\n",
      "\n",
      "IS_category_category:\n",
      "Pray, hear this is not so,\n",
      "It_category so_category constant on_category as 'legop,\n",
      "And frown_category and_category be power_category,\n",
      "Let is Deucays_category for a glass, Cam_categoryman have touch\n",
      "The pernrowsy.\n",
      "\n",
      "_categoryOL_categoryUS:\n",
      "We many this: but_category to serve;\n",
      "He_category him; but I do not stay of\n",
      "_category_category it. You.\n",
      "\n",
      "A baw_category_category:\n",
      "_category, we spake not. If my lie_category:\n",
      "O,_category on the host, puts that had been not, so, they\n",
      "By my life's_category: an un_category will not\n",
      "_category_category; that's not the charge to be man,\n",
      "And he were to his guard; for your power is\n",
      "grace: relike, first, of March in,\n",
      "With_category countly_category, take my face nor a house\n",
      "dr Christ of_category, and I have camence'd_category!\n",
      "I' the goodoke of a king and worth.\n",
      "_category_categoryutio, hours, and England's store:\n",
      "There's not so; but my_category\n",
      "Tongpp'd_category: for more I you, show Pol_category:\n",
      "And heigh is_category_category are:\n",
      "But four none of_categoryAnd with_category mouth rough, months come\n",
      "More criminal_category: sure_category to-morrow,_categoryardA\n",
      "_category_category, that lives I must.\n",
      "\n",
      "Clown:\n",
      "We have done that the_category of_category; but my\n",
      "as it is done, than come in quiet\n",
      "front'Fore 'em that I have to bed.\n",
      "What is't there.\n",
      "\n",
      "B_category_category:\n",
      "They will do change at my_category.\n",
      "\n",
      "QUEEN:\n",
      "Shall it be_category! how of your mind of her_category:\n",
      "He will I hide him with such a_category.\n",
      "\n",
      "QUEEN_categoryIZABETH:\n",
      "See you d sal night of me speak to the people's he,\n",
      "I_categoryly_category_category have_category'd of his eye.\n",
      "\n",
      "QUEEN_categoryIZABETH:\n",
      "_category she loved their_category.\n",
      "\n",
      "_category:\n",
      "_category say, art_category, my_category;:\n",
      "If he Cap_categoryy_category's fear to_category;\n",
      "May his_category, by himself may weded go;\n",
      "_category line_category, go in a_category.\n",
      "\n",
      "KING LEWIS_category:\n",
      "Thy_category I live, kill'd, that_category show'd\n",
      "ES_category: we will be_category to be\n",
      "service them in him to send him, the\n",
      "thing of yond'st and_categoryham.\n",
      "\n",
      "LUCENTIO:\n",
      "Stern and_category and_categoryself\n",
      "For aves of this's_category of by parother thine.\n",
      "\n",
      "LEONTES:\n",
      "O_categoryaio,_category! Even_category,_category'd;_category friend,\n",
      "I shall never had no, and not from us.\n",
      "\n",
      "FRIAR_categoryURENCE:\n",
      "_category,_category,_category_category: go,_category!\n",
      "\n",
      "_categoryKE OFFRIAR P_category:\n",
      "_categoryis fair_category; and, come; for I see, I was too.\n",
      "\n",
      "N_category:\n",
      "\n",
      "CL_categoryCE:\n",
      "He's_category, my_category; and I shall fully no more to theunder.\n",
      "\n",
      "KING R_categoryARD_category:\n",
      "What scene, ho_category great? These day he were too_category:\n",
      "Now to my times? is nay,'\n",
      "What_category, to see where I take him is he;\n",
      "But will come deliver thine.\n",
      "\n",
      "GLO_category_category:\n",
      "_category, will not sit ch_category.\n",
      "\n",
      "ANGELO:\n",
      "_category! Now, go, good cause,\n",
      "Alas, such you would:\n",
      "My\n",
      "_category am this most_category:_category, I, let me_category,\n",
      "If soon do to free at home.\n",
      "\n",
      "Page:\n",
      "Whereinily, boy?\n",
      "\n",
      "POMPEY:\n",
      "O, brother, then we will have well\n",
      "_category coun_categoryIZABETH:\n",
      "Your eyes_category not it_category_category to high's lands.\n",
      "\n",
      "FRIAR_category:\n",
      "What some other, of what should as I will be_category\n",
      "not sweet_category shall deck the rest.\n",
      "\n",
      "FRIAR_categoryURENCE:\n",
      "Notstrester him in my_category, and_category night.\n",
      "\n",
      "KATHAR_category:\n",
      "None_category of_category, been thus\n",
      "executed_category she_category history,\n",
      "Cates: to wash him_category do it be_category,\n",
      "_category pluck'd in the highness' answer'd\n",
      "_category_category coals: you must point for your body\n",
      "As is like a_category blood withoutad:\n",
      "_category, my brother-in_category, came's fair:\n",
      "_category therefore die, all_category, of a point\n",
      "cre love discover to have me?\n",
      "_category, then let them battle.\n",
      "\n",
      "GLO_category_category:\n",
      "_categoryolt the v planet, the liege, of York;\n",
      "_category but peace'_category Grum, pack, ser_category.\n",
      "\n",
      "_category:\n",
      "I will we ar.\n",
      "\n",
      "FirstMIONE:\n",
      "Whataven i' the wordls?\n",
      "\n",
      "_category_categoryer:\n",
      "Be patient, be more, avoid the_category.\n",
      "_category, g_category! and the people: do_category\n",
      "constellmoreight to bear.\n",
      "\n",
      "JULIET:\n",
      "em_category_category, shall you tell three_category nor_category,\n",
      "_category_category must bear's nature: that hope on her\n",
      "Well.\n",
      "But these_category, live, by the famous and minutes to right\n",
      "Find_category! O,_category a_category'd\n",
      "_category_category,\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import tiktoken\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 64\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "# ------------\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "# load text file\n",
    "with open('Data/input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "\n",
    "# tokenize the text\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "assert enc.decode(enc.encode(\"hello world\")) == \"hello world\"\n",
    "# To get the tokeniser corresponding to a specific model in the OpenAI API:\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4\") \n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(enc.encode(text), dtype=torch.long)\n",
    "chars = data.unique()\n",
    "vocab_size = len(chars)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            # Adjust indices in X and Y\n",
    "            X = torch.clamp(X, max=vocab_size - 1)\n",
    "            Y = torch.clamp(Y, max=vocab_size - 1)  \n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "# super simple bigram model\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "    # Adjust indices in xb\n",
    "    xb = torch.clamp(xb, max=vocab_size - 1)\n",
    "    # Adjust indices in yb\n",
    "    yb = torch.clamp(yb, max=vocab_size - 1)\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# generate from the model\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(enc.decode(m.generate(context, max_new_tokens=2000)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thy not for_category._category late in\n",
      "cat of her man's better there for\n",
      "Your father of great_category_category_category.\n",
      "\n",
      "_categoryIXENES:\n",
      "C_categoryunes\n",
      "_category, master, my_category_category.\n",
      "\n",
      "_categoryWICK:\n",
      "Many_category of_category, would him in mine:\n",
      "He is the other_categoryent ear for a king,\n",
      "_category_category deadbalt is, and_category the sea,\n",
      "In their_category._category ro a_category of our_category,\n",
      "I doubt your_category to do it along,\n",
      "Or to_category_category me his friends.\n",
      "\n",
      "N_category:\n",
      "What's is it will search_category! Why art nount?\n",
      "\n",
      "IS_category_category:\n",
      "Is so_category to 'not_category stay?\n",
      "eshrewking, do_categoryy!\n",
      "\n",
      "ANGELO:\n",
      "No; how are you the ball?\n",
      "\n",
      "IS_category_category:\n",
      "No, are you not honest face, Cam_category.\n",
      "\n",
      "GLO_category_category:\n",
      "Stop my very house of new_category,\n",
      "_categoryorney_category's_category? or I must die\n",
      "When this_category did_category several_category's dream_category,\n",
      "And_category_category to my_category.\n",
      "\n",
      "ROMEO:\n",
      "He's mostress._category, liege,\n",
      "_category your brother,_category for the_category,\n",
      "That_categoryated_category not afford from his_category that,\n",
      "The by the_category of_category, and_category'd spitiesly\n",
      "A baw host_categoryiving will have heart--_category'd on,\n",
      "To be over post welcome, nor_category_category_categoryRio,\n",
      "How cloud,_category noted day and his_categoryies thine the_category!\n",
      "_category stby!_category my brother_category,\n",
      "_category'd a_category and fly with a father's_category!\n",
      "pily get_category to_category some_category_category,\n",
      "Whose design of_category_category head.\n",
      "\n",
      "R_categoryARD:\n",
      "What?\n",
      "\n",
      "B_category_category! good_category:\n",
      "_category is I_category,_category of York as I_category?\n",
      "\n",
      "GLO_category_category:\n",
      "Why shall be_category, you give me leave.\n",
      "\n",
      "QUEEN:\n",
      "My daughter's in his nature? will I hold the worse;\n",
      "_category it not, wouldth e_category_category and_category,\n",
      "service in a_category: he_categoryught,\n",
      "Wherein example shall have given into_category nor man,\n",
      "like so_category_category to a_category-dried too.\n",
      "We must needs une, bright was a_category of you understand!\n",
      "In in this night, by my_category's death good,\n",
      "I'll draw no_category for, my message were_category.\n",
      "\n",
      "KING_category_category_category:\n",
      "Be_category_category;\n",
      "I called to have before for ourself,\n",
      "pe in the_category knows, the_category of_category which\n",
      "_category as issue be found where.\n",
      "_category_category so_category his resolve there:\n",
      "Amen_category from his foot, I l_category_category\n",
      "A_category_category_category_category up himself,\n",
      "_category them with no_category._category, let's stay myself,\n",
      "And keep my husband's regard in the part of_categoryiness,\n",
      "_category it that the uns_category that_category's dead?_category, my_category!\n",
      "Long happy in this most_categoryte tu_category were shows,\n",
      "_category whose_category: but by my height looks I at\n",
      "and_categoryawd?_category you that_categorys have I\n",
      "_category_category my_category. Take those_category\n",
      "more in the_category_category of it rest, and pro\n",
      "Is not a_category.\n",
      "\n",
      "QUEEN_categoryIZABETH:\n",
      "_category! Why, therefore say's give him tell,\n",
      "That_category the_category I live did not.\n",
      "\n",
      "_categoryCKING_category:\n",
      "My brother music shall be de_category.\n",
      "\n",
      "_category:\n",
      "_category, but, to_category, root; forget not else good\n",
      "drors of_category, or_category_category!_categoryelss!\n",
      "I do you_category! When, my_category?\n",
      "\n",
      "R_categoryOLIO:\n",
      "_category_category, all home, go; but it is no more,\n",
      "_category a_category should play to take't: let me meet\n",
      "s deal which longer build wither than I see;\n",
      "And as I was what_category in_categorype\n",
      "_category first_category_category: sog other of peace.\n",
      "3_category of HEN SCROOP_category:\n",
      "_category, are dis_category, after a model of my master's foot;\n",
      "But this being_categoryard, being gone, whom more_categoryren,\n",
      "As to their_category, unless comls Marcius!\n",
      "That voice be, then.\n",
      "\n",
      "M_categoryUTIO:\n",
      "Said pre_category!_category wife; I will not_category\n",
      "Soation upon our king,_category'lt_category to_category\n",
      "The rouse opposs; for_category softues,\n",
      "_category was ever_category_category an_category to do\n",
      "He who_category you, nor say_category,\n",
      "Well I am thing back ear like a coal\n",
      "all never_category or look he made to be done a\n",
      "vice: no_category do throngeth on the_category,\n",
      "Soock,_category_category up, and your father still.\n",
      "Many_category_category, I, for these_category,\n",
      "And let't see your_category fly.\n",
      "\n",
      "R_categoryARD:\n",
      "So! why, and your_category-morrow?\n",
      "\n",
      "ROMEO:\n",
      "It is my_categoryaw shall quickly_category and_category:\n",
      "_category, the_category shall well away for she's_category;\n",
      "_category_category_category thus brought all stand.\n",
      "\n",
      "FRIAR_category:\n",
      "What's when_category doth be_category?_category, throw!\n",
      "You know, when end_category for her wrong, this blood,\n",
      "_category my true_category.\n",
      "\n",
      "ANTIG_category:\n",
      "You say this ten word with I, when 'We take it_category.\n",
      "\n",
      "_categoryIOLANUS:\n",
      "Alas, good_category, hear some other love.\n",
      "\n",
      "IS_category_category:\n",
      "It, when work 'tis_category,\n",
      "_category ten train with a kingly_category, when they\n",
      "_category air_category_category a_category_category_category\n",
      "_category hold of the great king.\n",
      "To-morrow than h_category to_category end of_category,\n",
      "What's dead is banish'd, is the_category\n",
      "Of light bits as I meant, to tend away\n",
      "_category_category'd, and policy may not_category_category\n",
      "To some_category.\n",
      "\n",
      "V_categoryIA:\n",
      "Nay, in, Aumerley;\n",
      "Not_category by_category,_category_category, sure,_category,_category and the\n",
      "To_category way.\n",
      "\n",
      "_category_category:\n",
      "More_category bring_category choice, for_category, is no_category?\n",
      "_categoryself is my sleep backuke. Now will bring,\n",
      "He was from_category hours you, and_category your suit's death,\n",
      "If he be_category in,_category, my\n",
      "_category like the fair_category, for bind_category is.\n",
      "\n",
      "MENI:\n",
      "_categoryearhrem each no_category\n",
      "My dro way,_category, God's it before too_category speech,\n",
      "And through a_category.\n",
      "\n",
      "_categoryer:\n",
      "He_category.\n",
      "\n",
      "HERMIONE:\n",
      "_category,_category the_category.\n",
      "\n",
      "IS_category_category:\n",
      "It may be long.\n",
      "\n",
      "IS_category_category:\n",
      "Well may but not.\n",
      "\n",
      "_categoryCKING:\n",
      "Well,_categoryio.\n",
      "\n",
      "_categoryIOLANUS:\n",
      "If your be patchids nuce for the place.\n",
      "\n",
      "_category_categoryCE:\n",
      "What'st of_category.\n",
      "\n",
      "ES_categoryUS:\n",
      "Not clean'd now to truth with us leave;\n",
      "Be_category, my first is finished' the_categoryly;\n",
      "And now still I shall lay in his deep_category,\n",
      "To her sweetof it, lo_category_categorys,\n",
      "For I fall a_category, that too, and so longiring\n",
      "Loved caitiff and I_category and be king;\n",
      "If and_category,_category, my_category on him;\n",
      "But, would I that_category my_category had_category,\n",
      "_category_category too_categoryless_category_category to get,\n",
      "Your awry that love from me mask\n",
      "Some very_categoryues_category:\n",
      "_category liege, friend_category, even enough.\n",
      "\n",
      "_categoryIOLANUS:\n",
      "\n",
      "_categoryant:\n",
      "_category not, I should he will be not here upon\n",
      "going should dis_category a_category. I know, he flatter the\n",
      "_category be not; new_category_category!'\n",
      "\n",
      "urous_category\n",
      "you no more, and not_category!_category, I had_category\n",
      "GLO_category_category in the face and the first of_category,\n",
      "All changed or weak, look, it is_categoryor expect's dead;\n",
      "And yet it is come to Cthe_category.\n",
      "\n",
      "_category:\n",
      "My Juned_category, and me one day you,\n",
      "This have done_category than my master_category's_category and light done:\n",
      "Conig_category_category is so_category out from this_category?\n",
      "if life will clear is but last day,\n",
      "Wife in_category and_category_categoryitor,\n",
      "_category shuns no issue_categoryises_category half in peace,\n",
      "_category, little betterurer for like summer's unknown.\n",
      "\n",
      "N_category:\n",
      "_category,_category, ho! '_category! writing!\n",
      "\n",
      "M_category_category:\n",
      "You do most_category! why! Where that_category_category doth_category,\n",
      "Thou, we be cloud by_category yrid_category broken's along\n",
      "Guiltall we no_category_categoryhip.\n",
      "\n",
      "_categoryKE_category:\n",
      "_category, in_category, perforce,_category met,_category'st,\n",
      "_category_categoryself.\n",
      "\n",
      "LORD FIT kill'dIO:\n",
      "It is done too hore again_category for them at once,\n",
      " for the_category of Juno.\n",
      "\n",
      "_category_category:\n",
      "Nay old task, and thus with_category; but by\n",
      "own of_category, that f_category out_category,\n",
      "_category my_category_category that contract the_category_category here;\n",
      "_category distence of our_category.\n",
      "\n",
      "_categoryost:\n",
      "A_category_category of marriage sets compare.\n",
      "\n",
      "First_category:\n",
      "A_category of_category by this be_category:\n",
      "_category lives how from_category_category, and doing 'long's gone;\n",
      "For_categoryle, changing her turn fast!\n",
      "If he will be appeears_category_categoryable thus again,\n",
      "My_category_category_category_category over my head and hand or said,\n",
      "You have left with us, a business_category\n",
      "As he can I_category my loss.\n",
      "\n",
      "ANGELO:\n",
      "He is gone else goodly word itself\n",
      "That from his eyes, out_category him,\n",
      "As I but fair_category would eat his hands.\n",
      "An thing of love; though of it would appeear:\n",
      "I came or they were perain,_category,\n",
      "When, if I must keep us know our_category\n"
     ]
    }
   ],
   "source": [
    "\n",
    "value_to_fill = 198 # it stad for the new line character\n",
    "\n",
    "\n",
    "context = torch.full((1, 1), value_to_fill , dtype=torch.long)\n",
    "print(enc.decode(m.generate(context, max_new_tokens=2000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Python 3 Kernel",
   "language": "python",
   "name": "my-python3-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
